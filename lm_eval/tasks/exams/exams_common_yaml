task: null 
dataset_path: exams
dataset_name: null
output_type: multiple_choice
training_split: train
validation_split: validation
doc_to_text: "{{question.stem}}"
doc_to_target: "{{3 if answerKey.lstrip() not in question.choices.label else question.choices.label.index(answerKey.lstrip())}}" # answer as C if the answerKey is not in labels, this can happen in some corrupted rows.
doc_to_choice: "{{question.choices.text}}"
should_decontaminate: true
doc_to_decontamination_query: question_stem
metric_list:
  - metric: acc
    aggregation: mean
    higher_is_better: true
  - metric: acc_norm
    aggregation: mean
    higher_is_better: true
metadata:
  version: 0.0
